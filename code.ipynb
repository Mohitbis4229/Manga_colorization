{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "# === Configuration ===\n",
    "INPUT_PDF = None  # Set to None if no PDF is given\n",
    "OUTPUT_PDF = \"F:/test/ALL.pdf\"\n",
    "EXTRACTED_IMAGES_DIR = \"C:/gray/1\"\n",
    "PROCESSED_IMAGES_DIR = \"C:/gray/2\"\n",
    "AI_MODEL_PATH = \"F:/test/colorization_Model.keras\"\n",
    "PATCH_SIZE = 256  # Ensure this is set\n",
    "\n",
    "# === Step 1: Extract Images from PDF (if provided) ===\n",
    "def extract_images_from_pdf(pdf_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_count = 0\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        images = doc[page_num].get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            img_bytes = base_image[\"image\"]\n",
    "            img_ext = base_image[\"ext\"].lower()  # Ensure lowercase extension\n",
    "\n",
    "            # Convert WebP images to PNG for compatibility\n",
    "            if img_ext == \"webp\":\n",
    "                img_ext = \"png\"\n",
    "            \n",
    "            image_path = os.path.join(output_dir, f\"image_{image_count}.{img_ext}\")\n",
    "            with open(image_path, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "            print(f\"Extracted: {image_path}\")\n",
    "            image_count += 1\n",
    "\n",
    "    print(f\"Total Extracted Images: {image_count}\")\n",
    "\n",
    "# === Step 2: Load AI Model ===\n",
    "def load_ai_model(model_path):\n",
    "    print(\"Loading AI Model...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model Loaded Successfully.\")\n",
    "    return model\n",
    "\n",
    "# === Step 3: Process Image by Splitting, Running AI, and Reassembling ===\n",
    "def split_image(image, patch_size):\n",
    "    h, w, c = image.shape\n",
    "    patches, positions = [], []\n",
    "\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            patch = image[i:i+patch_size, j:j+patch_size]\n",
    "            \n",
    "            if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n",
    "                patch = cv2.copyMakeBorder(patch, 0, patch_size - patch.shape[0], \n",
    "                                                  0, patch_size - patch.shape[1], \n",
    "                                                  cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "            patches.append(patch)\n",
    "            positions.append((i, j))\n",
    "    \n",
    "    return patches, positions, (h, w)\n",
    "\n",
    "def process_patches(patches, model):\n",
    "    processed_patches = []\n",
    "    \n",
    "    for patch in patches:\n",
    "        if patch.shape[-1] == 3:\n",
    "            patch_gray = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            patch_gray = patch\n",
    "\n",
    "        patch_input = patch_gray / 255.0  # Normalize\n",
    "        patch_input = np.expand_dims(patch_input, axis=0)  # Add batch dimension\n",
    "        patch_input = np.expand_dims(patch_input, axis=-1)  # Ensure single-channel grayscale\n",
    "\n",
    "        processed_patch = model.predict(patch_input)[0]\n",
    "        processed_patch = np.squeeze(processed_patch)  # Remove extra dimensions\n",
    "        processed_patch = (processed_patch * 255).astype(np.uint8)\n",
    "\n",
    "        if len(processed_patch.shape) == 2:  \n",
    "            processed_patch = cv2.cvtColor(processed_patch, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        processed_patches.append(processed_patch)\n",
    "\n",
    "    return processed_patches\n",
    "\n",
    "def reassemble_image(patches, positions, original_size):\n",
    "    h, w = original_size\n",
    "    reconstructed_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for patch, (i, j) in zip(patches, positions):\n",
    "        patch = patch[:min(h-i, PATCH_SIZE), :min(w-j, PATCH_SIZE)]\n",
    "        reconstructed_image[i:i+patch.shape[0], j:j+patch.shape[1]] = patch\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "def process_image(image_path, model, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Skipping: Unable to read {image_path}\")\n",
    "        return\n",
    "    \n",
    "    patches, positions, original_size = split_image(image, PATCH_SIZE)\n",
    "    processed_patches = process_patches(patches, model)\n",
    "    reconstructed_image = reassemble_image(processed_patches, positions, original_size)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, reconstructed_image)\n",
    "    print(f\"Processed Image Saved: {output_path}\")\n",
    "\n",
    "# === Step 4: Convert Processed Images into PDF ===\n",
    "def convert_images_to_pdf(image_dir, output_pdf):\n",
    "    os.makedirs(os.path.dirname(output_pdf), exist_ok=True)  # Ensure output directory exists\n",
    "    images = []\n",
    "\n",
    "    for img_file in sorted(os.listdir(image_dir)):\n",
    "        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".webp\")):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            images.append(image)\n",
    "    \n",
    "    if images:\n",
    "        images[0].save(output_pdf, save_all=True, append_images=images[1:])\n",
    "        print(f\"Final PDF Created: {output_pdf}\")\n",
    "    else:\n",
    "        print(\"No images to convert into PDF.\")\n",
    "\n",
    "# === Main Execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    if INPUT_PDF:\n",
    "        print(f\"Extracting images from PDF: {INPUT_PDF}\")\n",
    "        extract_images_from_pdf(INPUT_PDF, EXTRACTED_IMAGES_DIR)\n",
    "    else:\n",
    "        print(\"No PDF provided. Skipping extraction.\")\n",
    "\n",
    "    if not os.listdir(EXTRACTED_IMAGES_DIR):\n",
    "        print(\"No images found for processing. Exiting...\")\n",
    "        exit()\n",
    "\n",
    "    ai_model = load_ai_model(AI_MODEL_PATH)\n",
    "\n",
    "    for img_file in os.listdir(EXTRACTED_IMAGES_DIR):\n",
    "        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".webp\")):\n",
    "            process_image(os.path.join(EXTRACTED_IMAGES_DIR, img_file), ai_model, PROCESSED_IMAGES_DIR)\n",
    "\n",
    "    convert_images_to_pdf(PROCESSED_IMAGES_DIR, OUTPUT_PDF)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
